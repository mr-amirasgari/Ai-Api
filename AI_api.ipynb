{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4aAZ8mAO2jzjOzWwnVhoS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-amirasgari/Ai-Api/blob/main/AI_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPn-RlN5jH1j"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a kind helpful PERSIAN assistant and response in Farsi and you can give me SQL Query\"},\n",
        "]"
      ],
      "metadata": {
        "id": "oblghbo9jqPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "\n",
        "    api_key=\"Ú©Ù„ÛŒØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\")\n",
        "\n",
        "stream = client.chat.completions.create(\n",
        "    messages=[\n",
        "\n",
        "              {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say this is a test\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    stream=True\n",
        "    )\n",
        "for chunk in stream:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RQm077ftkAPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"Ú©Ù„ÛŒØ¯ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\"\n",
        ")\n",
        "messages = []  # Initialize messages list\n",
        "\n",
        "while True:\n",
        "    message = input(\"User: \")\n",
        "    if message.lower() in [\"exit\", \"quit\"]:  # Allow user to exit\n",
        "        break\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    response = client.chat.completions.create(  # Updated function call\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    reply = response.choices[0].message.content\n",
        "    print(f\"ChatGPT: {reply}\")\n",
        "\n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})  # Save bot's response\n"
      ],
      "metadata": {
        "id": "xG-lanQCk4wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://api.avalai.ir/v1/models\"\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Ú©Ù„ÛŒØ¯Ø±Ø§ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\"\n",
        "}\n",
        "response = requests.get(url, headers=headers)\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "IDGuovg6sPTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai\n",
        "!pip install -U langchain\n",
        "!pip install -U langchain_openai"
      ],
      "metadata": {
        "id": "scL8_9Vnsx9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI # pip install -U openai\n",
        "\n",
        "client = OpenAI(\n",
        "base_url=\"https://api.avalai.ir/v1\",\n",
        "api_key=\"Ú©Ù„ÛŒØ¯Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\"\n",
        ")\n",
        "\n",
        "speech_file_path = \"./speech.mp3\"\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"alloy\",\n",
        "    input=\"......\"\n",
        ")\n",
        "response.stream_to_file(speech_file_path)"
      ],
      "metadata": {
        "id": "st33_7V4s3Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(base_url=\"https://api.avalai.ir/v1\", api_key=\"Ú©Ù„ÛŒØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\")\n",
        "response = client.images.generate(\n",
        "    model=\"dall-e-3\",\n",
        "    prompt=\"Hi This is Soheil from Maktabkhoone. you are learning AI and Machine learning and i am proud of you \",\n",
        "    size=\"1024x1024\",\n",
        "    quality=\"standard\",\n",
        "    n=1,\n",
        ")\n",
        "\n",
        "image_url = response.data[0].url"
      ],
      "metadata": {
        "id": "TRwKG1Vkvewp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url"
      ],
      "metadata": {
        "id": "6etMbJJvvufQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "# pip install -U langchain_openai\n",
        "import base64\n",
        "import os\n",
        "\n",
        "base_url = \"https://api.avalai.ir/v1\"\n",
        "api_key = \"Ú©Ù„ÛŒØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\"\n",
        "\n",
        "model_name = \"gpt-4o\"\n",
        "\n",
        "#model_name = \"gemini-2.0-flash-exp\"\n",
        "\n",
        "#model_name = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    base_url=base_url,\n",
        "    model=model_name,\n",
        "    api_key=api_key,\n",
        ")\n",
        "\n",
        "IMAGE_PATH = \"ØªØµÙˆÛŒØ±\"\n",
        "\n",
        "# Open the image file and encode it as a base64 string (safely)\n",
        "def encode_image(image_path):\n",
        "    if not os.path.exists(image_path):\n",
        "        return None, None\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\"), os.path.splitext(image_path)[1][1:]\n",
        "\n",
        "base64_image, image_ext = encode_image(IMAGE_PATH)\n",
        "\n",
        "if base64_image:\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a helpful Persian assistant.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"Tell me about this photo what is it, describe it in persian.\",\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/{image_ext};base64,{base64_image}\",\n",
        "                        \"detail\": \"auto\",\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "else:\n",
        "    # If the image file is missing, send a text-only request and warn the user.\n",
        "    print(f\"âš ï¸ Warning: image file not found at {IMAGE_PATH}. Sending text-only request.\")\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a helpful Persian assistant.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"Tell me about this photo what is it, describe it in persian.\",\n",
        "                }\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "\n",
        "ai_message = llm.invoke(messages)\n",
        "print(ai_message.content)\n"
      ],
      "metadata": {
        "id": "fLRJgBvNvvTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI # pip install -U openai\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.avalai.ir/v1\",\n",
        "    api_key=\"Ú©Ù„ÛŒØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\"\n",
        ")\n",
        "\n",
        "audio_file = open(\"speech.mp3\", \"rb\")\n",
        "transcription = client.audio.transcriptions.create(\n",
        "    model=\"whisper-1\",\n",
        "    file=audio_file,\n",
        "    response_format=\"text\"\n",
        ")\n",
        "print(transcription)\n"
      ],
      "metadata": {
        "id": "5jJOdm_cxjRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai\n",
        "!pip install -U langchain\n",
        "!pip install -U langchain_openai"
      ],
      "metadata": {
        "id": "NmnLsmB2x_-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import base64\n",
        "import os\n",
        "from io import BytesIO\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# API Configuration\n",
        "base_url = \"https://api.avalai.ir/v1\"\n",
        "api_key = \"Ú©Ù„ÛŒØ¯ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\"\n",
        "model_name = \"gpt-4o\"\n",
        "# Change model if needed: \"gemini-2.0-flash-exp\" or \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
        "\n",
        "# Initialize LangChain OpenAI Model\n",
        "llm = ChatOpenAI(\n",
        "    base_url=base_url,\n",
        "    model=model_name,\n",
        "    api_key=api_key,\n",
        ")\n",
        "\n",
        "# Function to Convert Image to Base64\n",
        "def encode_image_to_base64(image):\n",
        "    buffered = BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")  # Save as PNG for consistency\n",
        "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "# Function to Process Image and Get AI Description in Persian\n",
        "def analyze_image(image):\n",
        "    try:\n",
        "        # Convert Image to Base64\n",
        "        image_base64 = encode_image_to_base64(image)\n",
        "        image_ext = \"png\"  # Default format for uploaded images\n",
        "\n",
        "        # Messages for AI\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful Persian assistant.\"},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Describe the image in Farsi.\"},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/{image_ext};base64,{image_base64}\",\n",
        "                            \"detail\": \"auto\",\n",
        "                        },\n",
        "                    },\n",
        "                ],\n",
        "            },\n",
        "        ]\n",
        "\n",
        "        # Get AI-generated response\n",
        "        ai_message = llm.invoke(messages)\n",
        "\n",
        "        return ai_message.content  # Return AI description in Persian\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"âš ï¸ Ø®Ø·Ø§: {str(e)}\"\n",
        "\n",
        "# Gradio Web Interface\n",
        "iface = gr.Interface(\n",
        "    fn=analyze_image,\n",
        "    inputs=gr.Image(type=\"pil\"),  # Allow users to upload an image\n",
        "    outputs=gr.Textbox(label=\"ØªÙˆØ¶ÛŒØ­ ØªØµÙˆÛŒØ± ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ\"),\n",
        "    title=\"ğŸ–¼ï¸ ØªØ­Ù„ÛŒÙ„ ØªØµÙˆÛŒØ± Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ (Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ)\",\n",
        "    description=\"ØªØµÙˆÛŒØ±ÛŒ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯ ØªØ§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØªÙˆØ¶ÛŒØ­ÛŒ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø¢Ù† Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡Ø¯.\",\n",
        ")\n",
        "\n",
        "# Launch Web App\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "CTIteaUrzCKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "TBqEavp91Mlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "\n",
        "co = cohere.ClientV2(api_key=(\"Ú©Ù„ÛŒØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\"))\n",
        "\n",
        "res = co.chat(\n",
        "    model=\"command-r-plus-08-2024\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Ù…ØªÙ† Ø¯Ø±Ø®ÙˆØ§ÛŒØª Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯\",\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(res.message.content[0].text)\n",
        "# \"The Ultimate Guide to API Design: Best Practices for Building Robust and Scalable APIs\"\n"
      ],
      "metadata": {
        "id": "6AHZCwTu1Tl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"Ú©Ù„ÛŒØ¯ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  extra_headers={\n",
        "    \"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
        "    \"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
        "  },\n",
        "  model=\"openai/gpt-oss-120b:free\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"text\",\n",
        "          \"text\": \"Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø§ÛŒÙ† ØªØµÙˆÛŒØ± Ø¯Ø± Ù†Ù‚Ø´ ÛŒÚ© Ù…Ø¹Ù„Ù… Ù†Ù‚Ø§Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ú©ÙˆØ¯Ú©Ø§Ù† ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡. ØªÙˆØ¶ÛŒØ­ Ø¯Ø± Û²Û° Ú©Ù„Ù…Ù‡ Ø®Ù„Ø§ØµÙ‡ Ø´ÙˆØ¯\"\n",
        "        },\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": \"https://news-cdn.varzesh3.com/pictures/2025/08/13/D/15r3kcl17.webp?w=800\"\n",
        "          }\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "Df4c9M3-3Fhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "eF4vhVkK3Jv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "9eMtLfzQ4x8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI  # Make sure openai is installed: pip install -U openai\n",
        "\n",
        "# Initialize the OpenAI client with AvalAI API\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.avalai.ir/v1\",\n",
        "    api_key=\"Ú©Ù„ÛŒØ¯ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\"\n",
        ")\n",
        "\n",
        "# Function to generate speech and return audio file\n",
        "def text_to_speech(text):\n",
        "    speech_file_path = \"generated_speech.mp3\"  # Output file\n",
        "\n",
        "    try:\n",
        "        # Generate speech using AvalAI API\n",
        "        response = client.audio.speech.create(\n",
        "            model=\"tts-1\",\n",
        "            voice=\"alloy\",\n",
        "            input=text,\n",
        "        )\n",
        "\n",
        "        # Save the generated speech to a file\n",
        "        response.stream_to_file(speech_file_path)\n",
        "\n",
        "        return speech_file_path  # Returning the file path for playback & download\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"âš ï¸ Error: {str(e)}\"\n",
        "\n",
        "# Gradio UI\n",
        "iface = gr.Interface(\n",
        "    fn=text_to_speech,\n",
        "    inputs=gr.Textbox(label=\"Enter Text\"),\n",
        "    outputs=gr.Audio(label=\"Generated Speech\"),\n",
        "    title=\"ğŸ—£ï¸ AI-Powered Text-to-Speech (TTS)\",\n",
        "    description=\"Enter any text and get an AI-generated voice output using AvalAI.\",\n",
        ")\n",
        "\n",
        "# Launch the web app\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "2fCV-g4440Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# API Configuration\n",
        "base_url = \"https://api.avalai.ir/v1\"\n",
        "api_key = \"Ú©Ù„ÛŒØ¯ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\"  # Replace with your API key\n",
        "\n",
        "# Default model (Change if needed)\n",
        "model_name = \"gpt-4o\"\n",
        "\n",
        "# Initialize LangChain OpenAI Model\n",
        "def get_llm(model_name):\n",
        "    return ChatOpenAI(\n",
        "        model=model_name,\n",
        "        base_url=base_url,\n",
        "        api_key=api_key,\n",
        "    )\n",
        "\n",
        "# Function to handle user input\n",
        "def chat_with_ai(user_input, history, model_name):\n",
        "    llm = get_llm(model_name)  # Get LLM instance for selected model\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": \"ÛŒÚ© Ø¬ÙˆÚ© Ø®ÛŒÙ„ÛŒ Ø¨Ø§Ù…Ø²Ù‡ Ùˆ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ Ø´Ø±Ø§ÛŒØ· Ú©Ù…ØªØ± Ø§Ø² 200 Ú©Ù„Ù…Ù‡ Ø¨Ø§Ø´Ø¯ Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÛŒØ¯ Ùˆ Ù…ØªÙØ§ÙˆØª Ø¨Ø§Ø´Ø¯ Ø·ÙˆØ±ÛŒ Ú©Ù‡ ØªÚ©Ø±Ø§Ø±ÛŒ Ùˆ Ú©Ù„ÛŒØ´Ù‡â€ŒØ§ÛŒ Ù†Ø¨Ø§Ø´Ø¯ Ù…Ø­ØªÙˆØ§ÛŒ Ø³ÛŒØ§Ø³ÛŒ ÛŒØ§ ØªÙˆÙ‡ÛŒÙ†â€ŒØ¢Ù…ÛŒØ² Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ø¨ØªÙˆØ§Ù†Ù… Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ ØªØ¹Ø±ÛŒÙ Ú©Ù†Ù… Ø­ØªÛŒ Ø¯Ø± Ø¬Ù…Ø¹ Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ø´ÙˆØ®ÛŒ Ø¨Ø§ÛŒØ¯ Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡ Ùˆ ØºØ§ÙÙ„Ú¯ÛŒØ±Ú©Ù†Ù†Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ Ø´Ø®ØµÛŒØªâ€ŒÙ‡Ø§ Ùˆ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ø±Ø§ Ø·ÙˆØ±ÛŒ Ø¨Ø³Ø§Ø² Ú©Ù‡ Ø¯Ø± Ø°Ù‡Ù† Ø´Ù†ÙˆÙ†Ø¯Ù‡ ØªØµÙˆÛŒØ±Ø³Ø§Ø²ÛŒ Ø´ÙˆØ¯ Ù„Ø­Ù† Ø´ÛŒØ±ÛŒÙ† Ù¾Ø±Ø§Ù†Ø±Ú˜ÛŒ Ùˆ Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø± Ø¨Ø§Ø´Ø¯\"}]\n",
        "\n",
        "    # Add conversation history\n",
        "    for user_msg, bot_msg in history:\n",
        "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": bot_msg})\n",
        "\n",
        "    # Add current user input\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Get AI response\n",
        "    ai_message = llm.invoke(messages)\n",
        "\n",
        "    return ai_message.content  # Return AI response\n",
        "\n",
        "# Gradio Chat Interface\n",
        "chatbot = gr.ChatInterface(\n",
        "    fn=lambda message, history: chat_with_ai(message, history, model_name),\n",
        "    title=\"ğŸ’¬ AI Chatbot with GPT\",\n",
        "    description=\"Chat with AI models like GPT using API.\",\n",
        ")\n",
        "\n",
        "# Launch the Web App\n",
        "chatbot.launch()\n"
      ],
      "metadata": {
        "id": "F1Spm_oA5ngB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}